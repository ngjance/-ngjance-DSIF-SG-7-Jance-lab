{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.01 - Supervised Learning Model Comparison\n",
    "\n",
    "Recall the \"data science process.\"\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('../6_01-lab-supervised-learning-models/401ksubs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9275 entries, 0 to 9274\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   e401k   9275 non-null   int64  \n",
      " 1   inc     9275 non-null   float64\n",
      " 2   marr    9275 non-null   int64  \n",
      " 3   male    9275 non-null   int64  \n",
      " 4   age     9275 non-null   int64  \n",
      " 5   fsize   9275 non-null   int64  \n",
      " 6   nettfa  9275 non-null   float64\n",
      " 7   p401k   9275 non-null   int64  \n",
      " 8   pira    9275 non-null   int64  \n",
      " 9   incsq   9275 non-null   float64\n",
      " 10  agesq   9275 non-null   int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 797.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Number of dependants - More dependants, likely to have less funds for investments\n",
    "2. Occupations or Industry of work - If they are working in customer service sector versus Finance, unlikely to be interested in investment\n",
    "3. Highest level of education - the more educated, the higher the likelihood to know and understand about investment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It might be discriminating to certain race as it might suggest that only a certain race is/are interested in to invest in IRAs and 401k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Family size and marital status, as it is to have a lower correlation with income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "incsq and agesq. SMEs might have done it because they expected income and age to have a non-linear relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "INC looks like it is in per $1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- LogisticRegression\n",
    "- KNN\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Bagging\n",
    "- AdaBoost\n",
    "- SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector regressor\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('inc', axis=1)\n",
    "y=df['inc']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "ss=StandardScaler()\n",
    "X_train_scaled=ss.fit_transform(X_train)\n",
    "X_test_scaled=ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"LinearRegression\": LinearRegression(),\n",
    "          \"KNN\": KNeighborsRegressor(),\n",
    "          \"Decision Tree\": DecisionTreeRegressor(),\n",
    "          \"Random Forest\": RandomForestRegressor(),\n",
    "          \"Bagging\": BaggingRegressor(),\n",
    "          \"AdaBoost\": AdaBoostRegressor(),\n",
    "          \"SVR\": SVR(),\n",
    "          \"XGBoost\": xgb.XGBRegressor()\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "    results.append(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression Train Set Accuracy: 0.9042657299473781 \n",
      "LinearRegression Test Set Accuracy: 0.9103274918573819 \n",
      " \n",
      "KNN Train Set Accuracy: 0.9596754578810568 \n",
      "KNN Test Set Accuracy: 0.9369819355182614 \n",
      " \n",
      "Decision Tree Train Set Accuracy: 1.0 \n",
      "Decision Tree Test Set Accuracy: 0.9980229278705459 \n",
      " \n",
      "Random Forest Train Set Accuracy: 0.999989832777585 \n",
      "Random Forest Test Set Accuracy: 0.9980696616884012 \n",
      " \n",
      "Bagging Train Set Accuracy: 0.9999728432298366 \n",
      "Bagging Test Set Accuracy: 0.9979743116818105 \n",
      " \n",
      "AdaBoost Train Set Accuracy: 0.9920645524395331 \n",
      "AdaBoost Test Set Accuracy: 0.9928682109605583 \n",
      " \n",
      "SVR Train Set Accuracy: 0.878930227408786 \n",
      "SVR Test Set Accuracy: 0.8575650813565883 \n",
      " \n",
      "XGBoost Train Set Accuracy: 0.9999918822087891 \n",
      "XGBoost Test Set Accuracy: 0.9980641301734868 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_score = model.score(X_train_scaled, y_train)\n",
    "    test_score = model.score(X_test_scaled, y_test)\n",
    "    print(f\"{name} Train Set Accuracy: {train_score} \\n{name} Test Set Accuracy: {test_score} \\n \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bootstrapping is a resampling technique that involves repeatedly drawing samples from our source data with replacement, often to estimate a population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A decision tree categorize or make predictions based on how a previous set of questions were answered.<br>\n",
    "Bagging is an ensemble algorithm that fits multiple models on different subsets of a training dataset, then combines the predictions from all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bagging is an ensemble algorithm that fits multiple models on different subsets of a training dataset, then combines the predictions from all models.<br>\n",
    "Random forest is an extension of bagging that also randomly selects subsets of features used in each data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging reduces variance whereas boosting reduces bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression Training RMSE: 7.417805263260388 \n",
      "LinearRegression Testing RMSE: 7.349160927058248 \n",
      " \n",
      "KNN Training RMSE: 4.81422556749834 \n",
      "KNN Testing RMSE: 6.1608499133841335 \n",
      " \n",
      "Decision Tree Training RMSE: 6.022860099808153e-16 \n",
      "Decision Tree Testing RMSE: 1.0912376854990709 \n",
      " \n",
      "Random Forest Training RMSE: 0.07644390686945807 \n",
      "Random Forest Testing RMSE: 1.0782632756638775 \n",
      " \n",
      "Bagging Training RMSE: 0.12493403626090883 \n",
      "Bagging Testing RMSE: 1.1045729679596406 \n",
      " \n",
      "AdaBoost Training RMSE: 2.1356369471729457 \n",
      "AdaBoost Testing RMSE: 2.0725611012414524 \n",
      " \n",
      "SVR Training RMSE: 8.341796212933463 \n",
      "SVR Testing RMSE: 9.262246496856916 \n",
      " \n",
      "XGBoost Training RMSE: 0.06830628269742853 \n",
      "XGBoost Testing RMSE: 1.0798070886311009 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    rmse_train = mse(y_train, y_pred_train, squared=False)\n",
    "    rmse_test = mse(y_test, y_pred_test, squared=False)\n",
    "    print(f\"{name} Training RMSE: {rmse_train} \\n{name} Testing RMSE: {rmse_test} \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e401k', 0.0),\n",
       " ('inc', 0.0),\n",
       " ('marr', 0.0),\n",
       " ('male', 0.0),\n",
       " ('age', 0.0),\n",
       " ('fsize', 0.0),\n",
       " ('nettfa', 0.0),\n",
       " ('p401k', 0.0),\n",
       " ('pira', 1.0000000000000004),\n",
       " ('incsq', 0.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df.columns, models['AdaBoost'].feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN, Decision Tree, Random Forest, Bagging, SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost, very slight overfitting which can be ignored but higher accuracy compared to linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune max_depth, min_samples_split and min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p401k likely to be highly correlated with e401k, as if one is already participating in 401k, he/she is eligible for 401k.<br>\n",
    "Hence, it is not a very useful variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LogisticRegression\n",
    "- KNN\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Bagging\n",
    "- AdaBoost\n",
    "- SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector classifier\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('e401k', axis=1)\n",
    "y=df['e401k']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "ss=StandardScaler()\n",
    "X_train_scaled=ss.fit_transform(X_train)\n",
    "X_test_scaled=ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"LogisticRegression\": LogisticRegression(),\n",
    "          \"KNN\": KNeighborsClassifier(),\n",
    "          \"Decision Tree\": DecisionTreeClassifier(),\n",
    "          \"Random Forest\": RandomForestClassifier(),\n",
    "          \"Bagging\": BaggingClassifier(),\n",
    "          \"AdaBoost\": AdaBoostClassifier(),\n",
    "          \"SVC\": SVC(),\n",
    "          \"XGBoost\": xgb.XGBClassifier()\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "    results.append(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.89218329, 0.88005391, 0.89285714, 0.87735849, 0.87668464]),\n",
       " array([0.87398922, 0.85444744, 0.87398922, 0.85714286, 0.85983827]),\n",
       " array([0.80256065, 0.79514825, 0.81266846, 0.80660377, 0.80458221]),\n",
       " array([0.88477089, 0.87264151, 0.89016173, 0.87533693, 0.86792453]),\n",
       " array([0.87601078, 0.86455526, 0.87938005, 0.86792453, 0.86522911]),\n",
       " array([0.89218329, 0.88005391, 0.89285714, 0.87601078, 0.87668464]),\n",
       " array([0.89150943, 0.87735849, 0.89150943, 0.87601078, 0.87601078]),\n",
       " array([0.88140162, 0.86590296, 0.88342318, 0.86725067, 0.86455526])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Train Set Accuracy: 0.8838274932614555 \n",
      "LogisticRegression Test Set Accuracy: 0.8851752021563343 \n",
      " \n",
      "KNN Train Set Accuracy: 0.8943396226415095 \n",
      "KNN Test Set Accuracy: 0.8609164420485175 \n",
      " \n",
      "Decision Tree Train Set Accuracy: 1.0 \n",
      "Decision Tree Test Set Accuracy: 0.7800539083557951 \n",
      " \n",
      "Random Forest Train Set Accuracy: 1.0 \n",
      "Random Forest Test Set Accuracy: 0.8787061994609164 \n",
      " \n",
      "Bagging Train Set Accuracy: 0.9827493261455525 \n",
      "Bagging Test Set Accuracy: 0.8652291105121294 \n",
      " \n",
      "AdaBoost Train Set Accuracy: 0.8846361185983828 \n",
      "AdaBoost Test Set Accuracy: 0.8846361185983828 \n",
      " \n",
      "SVC Train Set Accuracy: 0.8842318059299191 \n",
      "SVC Test Set Accuracy: 0.8857142857142857 \n",
      " \n",
      "XGBoost Train Set Accuracy: 0.9311320754716981 \n",
      "XGBoost Test Set Accuracy: 0.8754716981132076 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_score = model.score(X_train_scaled, y_train)\n",
    "    test_score = model.score(X_test_scaled, y_test)\n",
    "    print(f\"{name} Train Set Accuracy: {train_score} \\n{name} Test Set Accuracy: {test_score} \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression y_pred_train: 0.2765498652291105\n",
      "    LogisticRegression y_pred_test RMSE: 0.2749326145552561\n",
      "    LogisticRegression Training RMSE: 0.34084088184744576\n",
      "    LogisticRegressionTesting RMSE: 0.3388580792067171\n",
      "\n",
      "KNN y_pred_train: 0.30835579514824796\n",
      "    KNN y_pred_test RMSE: 0.31212938005390833\n",
      "    KNN Training RMSE: 0.3250544221488004\n",
      "    KNNTesting RMSE: 0.3729390807511094\n",
      "\n",
      "Decision Tree y_pred_train: 0.39272237196765497\n",
      "    Decision Tree y_pred_test RMSE: 0.42749326145552563\n",
      "    Decision Tree Training RMSE: 0.0\n",
      "    Decision TreeTesting RMSE: 0.46898410596117734\n",
      "\n",
      "Random Forest y_pred_train: 0.39272237196765497\n",
      "    Random Forest y_pred_test RMSE: 0.28679245283018867\n",
      "    Random Forest Training RMSE: 0.0\n",
      "    Random ForestTesting RMSE: 0.34827259515942904\n",
      "\n",
      "Bagging y_pred_train: 0.3757412398921833\n",
      "    Bagging y_pred_test RMSE: 0.30566037735849055\n",
      "    Bagging Training RMSE: 0.13134182066062372\n",
      "    BaggingTesting RMSE: 0.36711154910717614\n",
      "\n",
      "AdaBoost y_pred_train: 0.27735849056603773\n",
      "    AdaBoost y_pred_test RMSE: 0.27547169811320754\n",
      "    AdaBoost Training RMSE: 0.33965258927559683\n",
      "    AdaBoostTesting RMSE: 0.33965258927559683\n",
      "\n",
      "SVC y_pred_train: 0.27695417789757415\n",
      "    SVC y_pred_test RMSE: 0.27547169811320754\n",
      "    SVC Training RMSE: 0.34024725431674074\n",
      "    SVCTesting RMSE: 0.3380617018914066\n",
      "\n",
      "XGBoost y_pred_train: 0.32493261455525607\n",
      "    XGBoost y_pred_test RMSE: 0.29649595687331537\n",
      "    XGBoost Training RMSE: 0.26242698894797745\n",
      "    XGBoostTesting RMSE: 0.352885678211503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    rmse_train = mse(y_train, y_pred_train, squared=False)\n",
    "    rmse_test = mse(y_test, y_pred_test, squared=False)\n",
    "    print(f\"{name} y_pred_train: {y_pred_train.mean()}\\n\\\n",
    "    {name} y_pred_test RMSE: {y_pred_test.mean()}\\n\\\n",
    "    {name} Training RMSE: {rmse_train}\\n\\\n",
    "    {name}Testing RMSE: {rmse_test}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "false positives: someone we predicted as eligible but is in fact not eligible<br>\n",
    "false negatives: someone we predicted as not eligible but is in fact eligible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minimize false positives, so that we do not waste resources targeting at the wrong audience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase precision and specificity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score is a harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression y_pred_train: 0.2765498652291105\n",
      "    LogisticRegression f1_score: 0.8264196536447845\n",
      "    LogisticRegression y_pred_test: 0.2749326145552561\n",
      "    LogisticRegression f1_score: 0.8272506082725061\n",
      "\n",
      "KNN y_pred_train: 0.30835579514824796\n",
      "    KNN f1_score: 0.8492887351018839\n",
      "    KNN y_pred_test: 0.31212938005390833\n",
      "    KNN f1_score: 0.8018433179723502\n",
      "\n",
      "Decision Tree y_pred_train: 0.39272237196765497\n",
      "    Decision Tree f1_score: 1.0\n",
      "    Decision Tree y_pred_test: 0.42749326145552563\n",
      "    Decision Tree f1_score: 0.7308707124010554\n",
      "\n",
      "Random Forest y_pred_train: 0.39272237196765497\n",
      "    Random Forest f1_score: 1.0\n",
      "    Random Forest y_pred_test: 0.28679245283018867\n",
      "    Random Forest f1_score: 0.8207171314741036\n",
      "\n",
      "Bagging y_pred_train: 0.3757412398921833\n",
      "    Bagging f1_score: 0.9775517362329007\n",
      "    Bagging y_pred_test: 0.30566037735849055\n",
      "    Bagging f1_score: 0.8062015503875968\n",
      "\n",
      "AdaBoost y_pred_train: 0.27735849056603773\n",
      "    AdaBoost f1_score: 0.827835880933226\n",
      "    AdaBoost y_pred_test: 0.27547169811320754\n",
      "    AdaBoost f1_score: 0.8265802269043759\n",
      "\n",
      "SVC y_pred_train: 0.27695417789757415\n",
      "    SVC f1_score: 0.8271281948078083\n",
      "    SVC y_pred_test: 0.27547169811320754\n",
      "    SVC f1_score: 0.8282009724473257\n",
      "\n",
      "XGBoost y_pred_train: 0.32493261455525607\n",
      "    XGBoost f1_score: 0.904037558685446\n",
      "    XGBoost y_pred_test: 0.29649595687331537\n",
      "    XGBoost f1_score: 0.8185388845247445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    print(f\"{name} y_pred_train: {y_pred_train.mean()}\\n\\\n",
    "    {name} f1_score: {f1_score(y_train, y_pred_train)}\\n\\\n",
    "    {name} y_pred_test: {y_pred_test.mean()}\\n\\\n",
    "    {name} f1_score: {f1_score(y_test, y_pred_test)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_AdaBoost = models['AdaBoost'].predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1131,    1],\n",
       "       [ 213,  510]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "confusion_matrix(y_test, \n",
    "                 y_pred_AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng_li\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(models['AdaBoost'], X_test_scaled, y_test, cmap='Blues', \n",
    "                      values_format='d', display_labels=['eligible', 'ineligible']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8265802269043759"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_AdaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN, DecisionTree, RandomForest, Bagging, AdBoost, XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdBoost and SVC produce very similar accuracy score and overfitting trade-off.<br>\n",
    "Given that SVC has slower processing when the data is huge, I would choose ADboost over SVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune n_estimators and learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regression: What features best predict one's income?<br>\n",
    "family size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
